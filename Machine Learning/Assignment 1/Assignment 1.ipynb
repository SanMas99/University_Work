{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0       1         0          1   31       1       0                     0   \n",
       "1       1         1          1   27       0       0                     0   \n",
       "2       0         1          1   32       1       0                     1   \n",
       "3       0         1          1   23       1       1                     0   \n",
       "4       0         1          1   37       1       0                     0   \n",
       "5       0         0          0   27       0       0                     0   \n",
       "6       0         1          1   37       1       0                     0   \n",
       "7       0         0          1   22       1       0                     0   \n",
       "8       1         0          1   17       1       0                     0   \n",
       "9       0         0          1   24       0       0                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  NoDocbcCost  GenHlth  MentHlth  \\\n",
       "0             0       0        0  ...            0        1         5   \n",
       "1             1       0        1  ...            0        2         0   \n",
       "2             0       1        1  ...            0        5         0   \n",
       "3             1       1        0  ...            0        2         0   \n",
       "4             0       0        1  ...            0        3        21   \n",
       "5             1       0        0  ...            1        4         0   \n",
       "6             1       0        0  ...            0        4         0   \n",
       "7             1       0        0  ...            0        2         0   \n",
       "8             0       1        1  ...            0        2        30   \n",
       "9             0       1        1  ...            1        2         0   \n",
       "\n",
       "   PhysHlth  DiffWalk  Sex  Age  Education  Income  class  \n",
       "0         0         0    0   10          4       7      0  \n",
       "1         0         0    0   11          5       7      0  \n",
       "2        15         1    0   10          5       5      0  \n",
       "3         3         0    0   12          5       8      0  \n",
       "4        14         1    0    6          5       1      0  \n",
       "5         0         0    1    7          5       3      0  \n",
       "6        30         0    0    9          4       5      0  \n",
       "7         0         0    1   10          6       8      0  \n",
       "8         0         0    1    4          4       4      0  \n",
       "9         4         0    0    8          5       5      0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"diabetes_70k.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the CSV file and see what the data looks like, making sure the data is loaded in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('class').values\n",
    "X = df.values\n",
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise all the models according to the assignment specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  fold val score [np.float64(0.6531573736742322), np.float64(0.732303556935585), np.float64(0.738428754838575), np.float64(0.7082415278870714), np.float64(0.7169976443189678)]\n",
      "6  fold val score [np.float64(0.6503564759803089), np.float64(0.736320941549256), np.float64(0.7388106150625248), np.float64(0.7098115769818367), np.float64(0.7169976800769536)]\n",
      "7  fold val score [np.float64(0.6517286912084301), np.float64(0.7345385541246517), np.float64(0.7391077477079003), np.float64(0.7080434188476337), np.float64(0.7168704205190055)]\n",
      "8  fold val score [np.float64(0.6519548687811182), np.float64(0.7359246977974874), np.float64(0.738923890062017), np.float64(0.710575505983756), np.float64(0.7166582918961917)]\n",
      "9  fold val score [np.float64(0.6521103029359292), np.float64(0.735938925203912), np.float64(0.738980347779539), np.float64(0.7103915014687471), np.float64(0.7167288120296694)]\n",
      "10  fold val score [np.float64(0.6546144000249711), np.float64(0.7342133141835089), np.float64(0.7387540855615379), np.float64(0.7081422882906281), np.float64(0.7169409836321424)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range (5,11):\n",
    "    cv_scoreList=[]   \n",
    "    for model in modelList:\n",
    "        kf = KFold(n_splits=k, shuffle = True)\n",
    "        cv_scoreList.append(np.mean(cross_val_score(model,x_norm,y,cv=kf)))\n",
    "    print(k, \" fold val score\", cv_scoreList)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using k-fold Cross validation, where k changes in value from the range 5-->10 the ranking is as follows for all k-fold cross validations:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Decision Tree Classifier where the max depth is 10\n",
    "    3. Gaussian Naive Bayes Classifier\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The ranking appears to be very stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6529451705992192, 0.7323883890680699, 0.7389237820404007, 0.711169580716347, 0.7207604820913257]\n",
      "[0.6535817348497709, 0.7312001358003735, 0.7382447801731454, 0.7113817687998641, 0.7189356645730776]\n",
      "[0.6616448820234255, 0.7344678322865388, 0.7407485995586488, 0.7082838227805126, 0.7182991003225259]\n",
      "[0.6550670514343915, 0.7393905958241385, 0.7390510948905109, 0.7117212697334918, 0.7212272958750636]\n",
      "[0.6501442878967917, 0.7317518248175182, 0.7399422848412833, 0.7099813274486505, 0.7186386012561534]\n",
      "[0.6504837888304192, 0.7277202512306908, 0.7338737056526905, 0.7086233237141402, 0.7146494652860296]\n",
      "[0.6521812934985571, 0.7286114411814633, 0.7393057205907316, 0.7073501952130369, 0.7208453573247326]\n",
      "[0.6580376846036327, 0.7332371414021388, 0.7366321507384145, 0.7082413851638092, 0.7180444746223053]\n",
      "[0.6531573586827364, 0.7335342047190629, 0.7390086572738075, 0.7098115769818367, 0.7180869122390087]\n",
      "[0.6556187404515362, 0.7328127652351044, 0.7374809030724835, 0.7103208283822781, 0.716983534204719]\n",
      "[0.6507808521473434, 0.7314971991172976, 0.7384994058733662, 0.7070955695128162, 0.713164148701409]\n",
      "[0.6517993549482262, 0.7297572568324563, 0.7373960278390765, 0.7062043795620438, 0.7139704634187743]\n",
      "[0.6461975895433713, 0.731921575284332, 0.7338737056526905, 0.7051010015277542, 0.7157528433203191]\n",
      "[0.6502291631301986, 0.7307333220166355, 0.740578849091835, 0.706883381429299, 0.720208793074181]\n",
      "[0.6495501612629435, 0.7303513834663046, 0.735910711254456, 0.7063316924121541, 0.7149040909862502]\n",
      "[0.6509930402308607, 0.7331098285520286, 0.7398574096078764, 0.7112544559497539, 0.7188083517229672]\n",
      "[0.64950772364624, 0.7344678322865388, 0.7394754710575454, 0.7109149550161263, 0.7203361059242913]\n",
      "[0.6498896621965711, 0.7302240706161942, 0.7355712103208284, 0.7075623832965541, 0.71736547275505]\n",
      "[0.6503989135970124, 0.7280597521643184, 0.7334493294856561, 0.7083686980139196, 0.7116788321167883]\n",
      "[0.64950772364624, 0.7284841283313529, 0.7356560855542352, 0.7057375657783059, 0.7138431505686641]\n",
      "[0.65208581 0.73168605 0.73767399 0.70861696 0.71732516]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_score=np.zeros(5)\n",
    "for i in range(0,20):\n",
    "    holdout_scoreList=[]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size=1/3,train_size=2/3,random_state=i+int(datetime.datetime.now().timestamp()))\n",
    "    for model in modelList:\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        holdout_scoreList.append(acc)\n",
    "    print(holdout_scoreList)\n",
    "    avg_score=np.add(avg_score,holdout_scoreList)\n",
    "avg_score=np.divide(avg_score,20)\n",
    "print(\"Average scores \",avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HoldOut, where 1/3 of the data is used as test and 2/3 is used as training data, the ranking is as follows:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Decision Tree Classifier where the max depth is 10\n",
    "    3. Gaussian Naive Bayes Classifier\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "Similar to k-fold, the ranking is the exact same and stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes_70k.csv\")\n",
    "downsized=df.sample(n=3000)\n",
    "y = downsized.pop('class').values\n",
    "X = downsized.values\n",
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reload the dataset the randomly sample 3000 values and then normalise the data values once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  fold val score [np.float64(0.663), np.float64(0.6913333333333334), np.float64(0.7336666666666666), np.float64(0.6983333333333333), np.float64(0.7233333333333334)]\n",
      "6  fold val score [np.float64(0.6536666666666667), np.float64(0.6963333333333334), np.float64(0.7326666666666667), np.float64(0.7016666666666667), np.float64(0.7229999999999999)]\n",
      "7  fold val score [np.float64(0.6446855325359999), np.float64(0.700010270103728), np.float64(0.7276586342006902), np.float64(0.6976730434674359), np.float64(0.7210025177314898)]\n",
      "8  fold val score [np.float64(0.651), np.float64(0.6973333333333334), np.float64(0.7343333333333333), np.float64(0.698), np.float64(0.726)]\n",
      "9  fold val score [np.float64(0.6520092947238657), np.float64(0.6970093846341352), np.float64(0.733665801530073), np.float64(0.6963300625975276), np.float64(0.725307143470816)]\n",
      "10  fold val score [np.float64(0.6529999999999999), np.float64(0.6973333333333332), np.float64(0.733), np.float64(0.6996666666666667), np.float64(0.7233333333333334)]\n"
     ]
    }
   ],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n",
    "\n",
    "for k in range (5,11):\n",
    "    cv_scoreList=[]   \n",
    "    for model in modelList:\n",
    "        kf = KFold(n_splits=k, shuffle = True)\n",
    "        cv_scoreList.append(np.mean(cross_val_score(model,x_norm,y,cv=kf)))\n",
    "    print(k, \" fold val score\", cv_scoreList)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using k-fold Cross validation, where k changes in value from the range 5-->10 the ranking for the sampled data is as follows for all k-fold cross validations:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Gaussian Naive Bayes Classifier\n",
    "    3. Decision Tree Classifier where the max depth is 10\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The KNN(k is 100) classifier and the Gaussian NB classifiers ranking's remains stable(KNN with 100 neighbours has the highest accuracy with Gaussian being the second highest) and fairly consistent in performance. This is different from the previous rankings in which Gaussian was the third most accurate, however with a smaller dataset it appears to be more accurate(could be overfitting).  The default decision tree classifier is consistently the weakest performing model, which matches the previous ranking. The default KNN and Decision tree whose depth is capped at 10 seem to switch rankings and isnt very stable but have similar performance. For 7 fold and 9 fold, the Decision tree is more accurate but for all other ones, the KNN is more accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.661, 0.685, 0.743, 0.695, 0.721]\n",
      "[0.646, 0.668, 0.718, 0.686, 0.701]\n",
      "[0.655, 0.691, 0.715, 0.684, 0.702]\n",
      "[0.625, 0.666, 0.718, 0.693, 0.704]\n",
      "[0.642, 0.677, 0.732, 0.7, 0.735]\n",
      "[0.646, 0.677, 0.736, 0.698, 0.72]\n",
      "[0.635, 0.674, 0.75, 0.712, 0.724]\n",
      "[0.647, 0.678, 0.73, 0.694, 0.73]\n",
      "[0.659, 0.689, 0.725, 0.705, 0.727]\n",
      "[0.61, 0.65, 0.708, 0.687, 0.717]\n",
      "[0.652, 0.678, 0.711, 0.686, 0.704]\n",
      "[0.646, 0.693, 0.73, 0.712, 0.735]\n",
      "[0.656, 0.662, 0.735, 0.682, 0.731]\n",
      "[0.649, 0.699, 0.739, 0.674, 0.743]\n",
      "[0.655, 0.685, 0.746, 0.704, 0.738]\n",
      "[0.65, 0.689, 0.727, 0.709, 0.725]\n",
      "[0.673, 0.693, 0.723, 0.696, 0.721]\n",
      "[0.644, 0.682, 0.732, 0.689, 0.715]\n",
      "[0.656, 0.691, 0.731, 0.682, 0.712]\n",
      "[0.64, 0.66, 0.724, 0.694, 0.73]\n",
      "[0.64735 0.67935 0.72865 0.6941  0.72175]\n"
     ]
    }
   ],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n",
    "\n",
    "avg_score=[0,0,0,0,0]\n",
    "for i in range(0,20):\n",
    "    holdout_scoreList=[]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size=1/3,train_size=2/3,random_state=i+int(datetime.datetime.now().timestamp()))\n",
    "    for model in modelList:\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        holdout_scoreList.append(acc)\n",
    "    print(holdout_scoreList)\n",
    "    avg_score=np.add(avg_score,holdout_scoreList)\n",
    "avg_score=np.divide(avg_score,20)\n",
    "print(\"Average scores \",avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HoldOut, where 1/3 of the sapled data is used as test and 2/3 is used as training data, the ranking is as follows:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Gaussian Naive Bayes Classifier\n",
    "    3. Decision Tree Classifier where the max depth is 10\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "Similar to k-fold, the rankings for KNN where n=100, Gaussian NB and default parameter Decision Trees is the exact same and stable. On average KNN has a higher accuracy than the Decision Tree classifier whose depth is limited to 10. However, in some reps, we can see that the Decision tree classifier has a slightly higher accuracy than the default KNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
