{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sanad Masannat\n",
    "\n",
    "ID: 24217734\n",
    "\n",
    "Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0       1         0          1   31       1       0                     0   \n",
       "1       1         1          1   27       0       0                     0   \n",
       "2       0         1          1   32       1       0                     1   \n",
       "3       0         1          1   23       1       1                     0   \n",
       "4       0         1          1   37       1       0                     0   \n",
       "5       0         0          0   27       0       0                     0   \n",
       "6       0         1          1   37       1       0                     0   \n",
       "7       0         0          1   22       1       0                     0   \n",
       "8       1         0          1   17       1       0                     0   \n",
       "9       0         0          1   24       0       0                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  NoDocbcCost  GenHlth  MentHlth  \\\n",
       "0             0       0        0  ...            0        1         5   \n",
       "1             1       0        1  ...            0        2         0   \n",
       "2             0       1        1  ...            0        5         0   \n",
       "3             1       1        0  ...            0        2         0   \n",
       "4             0       0        1  ...            0        3        21   \n",
       "5             1       0        0  ...            1        4         0   \n",
       "6             1       0        0  ...            0        4         0   \n",
       "7             1       0        0  ...            0        2         0   \n",
       "8             0       1        1  ...            0        2        30   \n",
       "9             0       1        1  ...            1        2         0   \n",
       "\n",
       "   PhysHlth  DiffWalk  Sex  Age  Education  Income  class  \n",
       "0         0         0    0   10          4       7      0  \n",
       "1         0         0    0   11          5       7      0  \n",
       "2        15         1    0   10          5       5      0  \n",
       "3         3         0    0   12          5       8      0  \n",
       "4        14         1    0    6          5       1      0  \n",
       "5         0         0    1    7          5       3      0  \n",
       "6        30         0    0    9          4       5      0  \n",
       "7         0         0    1   10          6       8      0  \n",
       "8         0         0    1    4          4       4      0  \n",
       "9         4         0    0    8          5       5      0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"diabetes_70k.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the CSV file and see what the data looks like, making sure the data is loaded in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('class').values\n",
    "X = df.values\n",
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data using the Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise all the models according to the assignment specifications and store it in a loop to make running all models more efficiently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  fold val score [np.float64(0.6514738541937024), np.float64(0.7376224523265165), np.float64(0.7387823135995983), np.float64(0.7092174596038077), np.float64(0.7166015036670201)]\n",
      "5  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "6  fold val score [np.float64(0.6488004300345159), np.float64(0.7342839359474905), np.float64(0.7384428223844282), np.float64(0.7101510779154644), np.float64(0.7171674305437673)]\n",
      "6  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "7  fold val score [np.float64(0.6515870887998589), np.float64(0.7335200671320147), np.float64(0.738372108318463), np.float64(0.7095993307149915), np.float64(0.7166864889586417)]\n",
      "7  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "8  fold val score [np.float64(0.6506536166201687), np.float64(0.7353448346961695), np.float64(0.738626825943719), np.float64(0.7097833771572291), np.float64(0.7169553528127985)]\n",
      "8  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "9  fold val score [np.float64(0.6518841802999515), np.float64(0.7346377961198046), np.float64(0.7384004330535201), np.float64(0.7100945318041959), np.float64(0.7167995600017166)]\n",
      "9  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "10  fold val score [np.float64(0.6516155203217108), np.float64(0.7356700621055375), np.float64(0.7393198524225641), np.float64(0.7095286970242606), np.float64(0.716757218150528)]\n",
      "10  fold val model ranking ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n"
     ]
    }
   ],
   "source": [
    "models=[\"Default DecisionTree Classifier\", \"DecisionTree Classifier with Depth capped at 10\", \"KNeighborsClassifier where n = 100\", \"Default KNeighbours\", \"Gaussian Naive Bayes\"]\n",
    "# The above isjust used to map rank indices to models\n",
    "for k in range (5,11):\n",
    "    cv_scoreList=[]\n",
    "    for model in modelList:\n",
    "        kf = KFold(n_splits=k, shuffle = True)#Initalise folds\n",
    "        cv_scoreList.append(np.mean(cross_val_score(model,x_norm,y,cv=kf)))# Get accuracies, get an average and store them\n",
    "    rank = np.argsort(cv_scoreList)[::-1]#Get rankings from the scorelist to see which performs better\n",
    "    ranked_models = [models[i] for i in rank]# Map indices to models\n",
    "    print(k, \" fold val score\", cv_scoreList)\n",
    "    print(k, \" fold val model ranking\", ranked_models)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using k-fold Cross validation, where k changes in value from the range 5-->10 the ranking is as follows for all k-fold cross validations:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Decision Tree Classifier where the max depth is 10\n",
    "    3. Gaussian Naive Bayes Classifier\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The ranking appears to be very stable likely due to the large dataset allowing the models to be more closely fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model2=DecisionTreeClassifier(max_depth=10)\n",
    "model3=KNeighborsClassifier(n_neighbors = 100)\n",
    "model4=KNeighborsClassifier()\n",
    "model5=GaussianNB()\n",
    "modelList=[model1,model2,model3,model4,model5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6572313698862672, 0.735910711254456, 0.7412578509590901, 0.7107452045493126, 0.7180020370056017]\n",
      "Rank for iteration  1 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6508232897640468, 0.7340858937362078, 0.7373535902223731, 0.7045917501273129, 0.7143524019691054]\n",
      "Rank for iteration  2 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.655406552368019, 0.7365897131217111, 0.7406212867085384, 0.7100237650653539, 0.7202936683075879]\n",
      "Rank for iteration  3 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.653114921066033, 0.7283992530979461, 0.7375233406891869, 0.7101935155321677, 0.7149465286029537]\n",
      "Rank for iteration  4 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6586318112374809, 0.736674588355118, 0.7408759124087592, 0.7138431505686641, 0.7220336105924291]\n",
      "Rank for iteration  5 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6500169750466814, 0.7325157019181803, 0.7379052792395179, 0.710787642166016, 0.7156255304702088]\n",
      "Rank for iteration  6 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6512901035477847, 0.7335766423357665, 0.7399847224579867, 0.7105754540824988, 0.7176200984552707]\n",
      "Rank for iteration  7 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6590137497878119, 0.7325581395348837, 0.7364199626548973, 0.7052283143778645, 0.7156255304702088]\n",
      "Rank for iteration  8 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6543031743337294, 0.7295875063656425, 0.7383720930232558, 0.7072228823629265, 0.7180020370056017]\n",
      "Rank for iteration  9 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6514174163978951, 0.7313274486504838, 0.7362926498047869, 0.7104481412323884, 0.7198692921405534]\n",
      "Rank for iteration  10 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.650356475980309, 0.7313698862671872, 0.7340010185028009, 0.708029197080292, 0.7132065863181124]\n",
      "Rank for iteration  11 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6505262264471228, 0.7300543201493804, 0.7321337633678493, 0.7066711933457817, 0.7157952809370226]\n",
      "Rank for iteration  12 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6527754201324054, 0.7348922084535733, 0.737056526905449, 0.7100237650653539, 0.7132914615515192]\n",
      "Rank for iteration  13 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6509081649974537, 0.7306060091665252, 0.7394754710575454, 0.7094720760482092, 0.7190205398064845]\n",
      "Rank for iteration  14 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6527754201324054, 0.7286538787981667, 0.7354863350874215, 0.7114666440332711, 0.7189356645730776]\n",
      "Rank for iteration  15 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6526905448989985, 0.7337463928025802, 0.7396452215243592, 0.7112544559497539, 0.7157952809370226]\n",
      "Rank for iteration  16 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6517144797148192, 0.7272109998302495, 0.7343405194364284, 0.7089203870310643, 0.7140129010354779]\n",
      "Rank for iteration  17 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6531573586827364, 0.7356985231709388, 0.7433797317942624, 0.7154133423866915, 0.7203785435409947]\n",
      "Rank for iteration  18 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6500594126633849, 0.7347224579867595, 0.737820404006111, 0.7102783907655746, 0.7172381599049398]\n",
      "Rank for iteration  19 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.6532846715328468, 0.7331098285520286, 0.7369292140553386, 0.7112544559497539, 0.715073841453064]\n",
      "Rank for iteration  20 ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "Average scores  [0.65297488 0.73256451 0.73784374 0.70982219 0.71695595]\n",
      "Avg Ranking:  ['KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Gaussian Naive Bayes', 'Default KNeighbours', 'Default DecisionTree Classifier']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_score=np.zeros(5)\n",
    "for i in range(0,20):\n",
    "    holdout_scoreList=[]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size=1/3,train_size=2/3,random_state=i+int(datetime.datetime.now().timestamp()))\n",
    "    # We split the data according to the specified 2:1 and use current time plus iteration as your seed value\n",
    "    for model in modelList:\n",
    "        #here we train the model, then predict the values and from there check accuracy\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        holdout_scoreList.append(acc)\n",
    "    print(holdout_scoreList)\n",
    "    rank = np.argsort(holdout_scoreList)[::-1]\n",
    "    ranked_models = [models[i] for i in rank]\n",
    "    print(\"Rank for iteration \",i+1 , ranked_models)\n",
    "    avg_score=np.add(avg_score,holdout_scoreList)#Get total score of each model to later calculate an average\n",
    "avg_score=np.divide(avg_score,20)#Average the model accuracies over the 20 iterations done\n",
    "print(\"Average scores \",avg_score)\n",
    "avg_rank_idx = np.argsort(avg_score)[::-1]\n",
    "avg_rank = [models[i] for i in avg_rank_idx]\n",
    "print(\"Avg Ranking: \", avg_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HoldOut, where 1/3 of the data is used as test and 2/3 is used as training data, the ranking is as follows:\n",
    "\n",
    "    1. KNN Classifier where n is 100\n",
    "    2. Decision Tree Classifier where the max depth is 10\n",
    "    3. Gaussian Naive Bayes Classifier\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The ranking is the exact same as the ranking for the k-fold validation and is very stable for the same reason(large dataset allowing the models to be more closely fitted). They both exhibit similar accuracies as well so for large datsets, one can use either hold-out or cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes_70k.csv\")\n",
    "downsized=df.sample(n=3000)\n",
    "y = downsized.pop('class').values\n",
    "X = downsized.values\n",
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reload the dataset the randomly sample 3000 values and then normalise the data values once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  fold val score [np.float64(0.6556666666666666), np.float64(0.677), np.float64(0.7393333333333334), np.float64(0.7063333333333333), np.float64(0.7423333333333334)]\n",
      "5  fold val model ranking ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "6  fold val score [np.float64(0.6506666666666666), np.float64(0.6683333333333333), np.float64(0.7370000000000001), np.float64(0.7093333333333334), np.float64(0.739)]\n",
      "6  fold val model ranking ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "7  fold val score [np.float64(0.6639917714684069), np.float64(0.6819932404044554), np.float64(0.7389962062859258), np.float64(0.7083360564668976), np.float64(0.740334431923217)]\n",
      "7  fold val model ranking ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "8  fold val score [np.float64(0.6513333333333333), np.float64(0.6930000000000001), np.float64(0.7446666666666666), np.float64(0.7133333333333334), np.float64(0.742)]\n",
      "8  fold val model ranking ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "9  fold val score [np.float64(0.6476536416656177), np.float64(0.6896916876956798), np.float64(0.7420004835174496), np.float64(0.7136737535939133), np.float64(0.736670802539066)]\n",
      "9  fold val model ranking ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "10  fold val score [np.float64(0.6583333333333334), np.float64(0.6886666666666665), np.float64(0.7426666666666667), np.float64(0.7176666666666667), np.float64(0.7366666666666666)]\n",
      "10  fold val model ranking ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n"
     ]
    }
   ],
   "source": [
    "models=[\"Default DecisionTree Classifier\", \"DecisionTree Classifier with Depth capped at 10\", \"KNeighborsClassifier where n = 100\", \"Default KNeighbours\", \"Gaussian Naive Bayes\"]\n",
    "for k in range (5,11):\n",
    "    cv_scoreList=[]\n",
    "    for model in modelList:\n",
    "        kf = KFold(n_splits=k, shuffle = True)\n",
    "        cv_scoreList.append(np.mean(cross_val_score(model,x_norm,y,cv=kf)))\n",
    "    rank = np.argsort(cv_scoreList)[::-1]\n",
    "    ranked_models = [models[i] for i in rank]\n",
    "    print(k, \" fold val score\", cv_scoreList)\n",
    "    print(k, \" fold val model ranking\", ranked_models)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using k-fold Cross validation, where k changes in value from the range 5-->10 the stable ranking for the sampled data were as follows for all k-fold cross validations:\n",
    "\n",
    "    3. Decision Tree Classifier where the max depth is 10\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The main unstability here is that for smaller k values, Gaussian was the better (more accurate) model compared to the KNeighbours where n is 100 model. This could be because Gaussian performs better at lower k values or due to a smaller dataset. The latter is more probable as it was consistently 3rd when using the full dataset. KNeighbours appears to need a larger datasetto perform better. The average accuracy appears to be similar to each other (small drops in accuracy albeit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.664, 0.701, 0.736, 0.715, 0.737]\n",
      "Rank for iteration  1 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.649, 0.685, 0.743, 0.706, 0.744]\n",
      "Rank for iteration  2 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.647, 0.677, 0.733, 0.699, 0.734]\n",
      "Rank for iteration  3 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.648, 0.684, 0.72, 0.706, 0.73]\n",
      "Rank for iteration  4 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.666, 0.693, 0.73, 0.704, 0.736]\n",
      "Rank for iteration  5 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.643, 0.68, 0.741, 0.716, 0.742]\n",
      "Rank for iteration  6 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.634, 0.675, 0.754, 0.717, 0.755]\n",
      "Rank for iteration  7 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.64, 0.669, 0.744, 0.707, 0.754]\n",
      "Rank for iteration  8 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.636, 0.674, 0.726, 0.704, 0.735]\n",
      "Rank for iteration  9 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.66, 0.684, 0.735, 0.714, 0.747]\n",
      "Rank for iteration  10 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.624, 0.656, 0.728, 0.71, 0.726]\n",
      "Rank for iteration  11 ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.66, 0.678, 0.73, 0.702, 0.734]\n",
      "Rank for iteration  12 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.654, 0.682, 0.735, 0.711, 0.743]\n",
      "Rank for iteration  13 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.621, 0.674, 0.735, 0.699, 0.735]\n",
      "Rank for iteration  14 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.636, 0.694, 0.727, 0.711, 0.739]\n",
      "Rank for iteration  15 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.639, 0.682, 0.746, 0.711, 0.74]\n",
      "Rank for iteration  16 ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.654, 0.659, 0.731, 0.707, 0.734]\n",
      "Rank for iteration  17 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.642, 0.694, 0.719, 0.693, 0.731]\n",
      "Rank for iteration  18 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'DecisionTree Classifier with Depth capped at 10', 'Default KNeighbours', 'Default DecisionTree Classifier']\n",
      "[0.636, 0.689, 0.734, 0.711, 0.727]\n",
      "Rank for iteration  19 ['KNeighborsClassifier where n = 100', 'Gaussian Naive Bayes', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "[0.661, 0.696, 0.748, 0.712, 0.754]\n",
      "Rank for iteration  20 ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n",
      "Average scores  [0.6457  0.6813  0.73475 0.70775 0.73885]\n",
      "Avg Ranking:  ['Gaussian Naive Bayes', 'KNeighborsClassifier where n = 100', 'Default KNeighbours', 'DecisionTree Classifier with Depth capped at 10', 'Default DecisionTree Classifier']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_score=np.zeros(5)\n",
    "for i in range(0,20):\n",
    "    holdout_scoreList=[]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size=1/3,train_size=2/3,random_state=i+int(datetime.datetime.now().timestamp()))\n",
    "    for model in modelList:\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        holdout_scoreList.append(acc)\n",
    "    print(holdout_scoreList)\n",
    "    rank = np.argsort(holdout_scoreList)[::-1]\n",
    "    ranked_models = [models[i] for i in rank]\n",
    "    print(\"Rank for iteration \",i+1 , ranked_models)\n",
    "    avg_score=np.add(avg_score,holdout_scoreList)\n",
    "avg_score=np.divide(avg_score,20)\n",
    "avg_rank_idx = np.argsort(avg_score)[::-1]\n",
    "avg_rank = [models[i] for i in avg_rank_idx]\n",
    "print(\"Average scores \",avg_score)\n",
    "\n",
    "print(\"Avg Ranking: \", avg_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HoldOut, where 1/3 of the sampled data is used as test and 2/3 is used as training data, the average ranking is as follows:\n",
    "\n",
    "    1. Gaussian Naive Bayes Classifier\n",
    "    2. KNN Classifier where n is 100\n",
    "    3. Decision Tree Classifier where the max depth is 10\n",
    "    4. KNN Classifier with default parameters\n",
    "    5. Decision Tree Classifier with default parameters\n",
    "\n",
    "The ranking isnt as stable as when we used the full dataset. THis could be because we have a smaller dataset, leading to models being more fitted to the data and having similar performances and a smaller training data. For example, the Gaussian Naive Bayes performed better than other models with the smaller dataset (with the expection of iterations 19 and 16), followed by KNeighbours where k is 100. With the exception of iteration 18, the ranking was Default KNeighbours --> DecisionTree Classifier with Depth capped at 10 --> Default DecisionTree Classifier. It seems a decision tree performs worse with a smaller dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
