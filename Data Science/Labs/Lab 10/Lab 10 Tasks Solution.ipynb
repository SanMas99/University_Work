{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 Tasks - Solution\n",
    "\n",
    "In this we will look at using superised machine learning algorithms to predict music genres. Specficially, the objective here is to classify the genre of a song from Spotify, based on a range of associated audio features.\n",
    "\n",
    "Each song in our dataset is described by a range of features:\n",
    "- artist_name: Song artist \n",
    "- track_name: Song track name\n",
    "- acousticness: Describes the likelihood that the song is purely acoustic\n",
    "- danceability: Describes how suitable a track is for dancing based on a combination of elements including tempo, rhythm stability, beat strength, and overall regularity\n",
    "- energy: A perceptual measure of intensity and activity. More energetic tracks feel fast, loud, and noisy\n",
    "- instrumentalness: Indicates whether a song includes vocals or not\n",
    "- liveness: Describes the likelihood that the song was recorded with a live audience.\n",
    "- loudness: Overall loudness of a track in decibels (dB), averaged across the entire track\n",
    "- speechiness:  Describes the likelihood that the song contains spoken words\n",
    "- tempo: Estimated tempo of a track in beats per minute (BPM)\n",
    "- valence: Tracks with high valence sound more positive (e.g. cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, angry)\n",
    "- genre: Target label ('Pop' or 'Rock' in this case)\n",
    "\n",
    "Original dataset source: \n",
    "https://www.kaggle.com/code/iqbalbasyar/spotify-genre-classification/data\n",
    "\n",
    "Original Spotify documentation:\n",
    "https://developer.spotify.com/discover/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# imports for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Load the dataset from the file 'music.csv' and examine the number of songs having each target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"music.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number with each class label\n",
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any non-numeric features from the dataset, and then separate out the features to use for classification from the target label information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the non-numeric features\n",
    "df.drop([\"artist_name\", \"track_name\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target label\n",
    "target = df[\"genre\"]\n",
    "# remove the target label, giving us just the numeric feratures for classification\n",
    "data = df.drop(\"genre\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Generate a 60/40 random training and test split of the data. Based on this split, evaluate the accuracy and F1-score achieved by a KNN classifier (for *k=1* neighbour). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# use 60% for training, 40% for testing\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, \n",
    "    test_size=0.4, random_state=1)\n",
    "print(\"Training set has %d examples\" % data_train.shape[0])\n",
    "print(\"Test set has %d examples\" % data_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "m = knn.fit(data_train, target_train)\n",
    "# make predictions for the test set\n",
    "predicted = knn.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(target_test, predicted)\n",
    "print(\"Accuracy=%.3f\" % acc)\n",
    "# evalaute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1(Rock) = %.3f\" % f1_score(target_test, predicted, pos_label=\"Rock\") )\n",
    "print(\"F1(Pop) = %.3f\" % f1_score(target_test, predicted, pos_label=\"Pop\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a *confusion matrix* to illustrate where the errors lie with the classifier above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# build the confusion matrix\n",
    "cm = confusion_matrix(target_test, predicted)\n",
    "# display it visually\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use 5-fold cross-validation to evaluate the accuracy achieved by a KNN (*k=1*) classifier on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "fold_scores = cross_val_score(knn, data, target, cv=5, scoring=\"accuracy\")\n",
    "mean_accuracies = {1: fold_scores.mean()}\n",
    "print(\"KNN (k=1): Mean cross-validation accuracy = %.3f\" % mean_accuracies[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the process above for different parameter values of *k*, from 2 to 10 neighbours. Generate a plot of the different accuracy values acheived for different values of *k*. Which value of *k* yields the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,11):\n",
    "    # apply KNN for the specified value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    fold_scores = cross_val_score(knn, data, target, cv=5, scoring=\"accuracy\")\n",
    "    mean_accuracies[k] = fold_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the plot\n",
    "df_mean_accuracies = pd.Series(mean_accuracies)\n",
    "ax = df_mean_accuracies.plot(figsize=(9.5,6), fontsize=14, lw=2, marker='o', color=\"darkorange\")\n",
    "ax.set_ylabel(\"Cross-validation Accuracy\", fontsize=14)\n",
    "ax.set_xlabel(\"Number of Neighbours (k)\", fontsize=14)\n",
    "ax.yaxis.grid()\n",
    "ax.set_xlim(1, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the values to see the parameter giving the highest accuracy\n",
    "df_sorted = df_mean_accuracies.sort_values(ascending=False)\n",
    "print(df_sorted)\n",
    "# get the value of k which gives the highest accuracy\n",
    "best_k = df_sorted.index[0]\n",
    "print(\"Best value is k=%d\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "For certain datasets, classification may work better on a subset of features, rather than on the entire feature set (e.g. when noisy or misleading features are removed).\n",
    "\n",
    "Using the KNN and the best value of *k* identified in Task 3, compare classification performance for the three feature subsets in the lists below. Which subset gives the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = ['danceability', 'energy', 'tempo', 'valence']\n",
    "subset2 = ['acousticness', 'instrumentalness', 'liveness', 'speechiness']\n",
    "subset3 = ['energy', 'tempo', 'valence', 'loudness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the first subset of features\n",
    "data1 = data[subset1]\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "fold_scores = cross_val_score(knn, data1, target, cv=5, scoring=\"accuracy\")\n",
    "mean_acc1 = fold_scores.mean()\n",
    "print(\"Subset 1 - KNN (k=%d): Mean cross-validation accuracy = %.3f\" % (best_k, mean_acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the second subset of features\n",
    "data2 = data[subset2]\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "fold_scores = cross_val_score(knn, data2, target, cv=5, scoring=\"accuracy\")\n",
    "mean_acc2 = fold_scores.mean()\n",
    "print(\"Subset 2 - KNN (k=%d): Mean cross-validation accuracy = %.3f\" % (best_k, mean_acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the third subset of features\n",
    "data3 = data[subset3]\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "fold_scores = cross_val_score(knn, data3, target, cv=5, scoring=\"accuracy\")\n",
    "mean_acc3 = fold_scores.mean()\n",
    "print(\"Subset 3 - KNN (k=%d): Mean cross-validation accuracy = %.3f\" % (best_k, mean_acc3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
